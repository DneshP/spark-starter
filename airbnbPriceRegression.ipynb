{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e0fe805-8aaf-4e7d-bde1-9b9241236bff",
   "metadata": {},
   "source": [
    "### Airbnb Dataset Analysis and Regression Modeling with Spark\n",
    "\n",
    "This code snippet illustrates a simplified data analysis and regression modeling workflow using the Airbnb dataset with Apache Spark. The dataset is loaded in Parquet format, and basic preprocessing steps are undertaken to ready it for regression modeling. Two regression models, Linear Regression and RandomForestRegressor, are employed for predicting the \"price\" variable.\n",
    "\n",
    "**Dataset Source and Copyright:**\n",
    "The data for this analysis is sourced from [Inside Airbnb](http://insideairbnb.com/get-the-data.html). All copyrights and ownership of the data belong to the respective owner.\n",
    "\n",
    "**Dataset and Preprocessing:**\n",
    "The Airbnb dataset is loaded and explored, revealing its schema. Categorical and numeric columns are identified for subsequent preprocessing. Numeric features undergo imputation, vectorization, and scaling, while categorical features are indexed, one-hot encoded, and combined with the scaled numeric features.\n",
    "\n",
    "**Regression Modeling:**\n",
    "Two regression models, Linear Regression and RandomForestRegressor, are trained on the preprocessed data. Predictions are made on a test set, and the root mean square error (RMSE) is computed to evaluate the model performance.\n",
    "\n",
    "- Linear Regression RMSE: 220.6\n",
    "- Random Forest RMSE: 207.7\n",
    "\n",
    "**MLflow Integration:**\n",
    "MLflow is introduced to log the model parameters, metrics, and an artifact containing feature importance scores. The logged information is organized within an MLflow run for easy tracking and reproducibility.\n",
    "\n",
    "**Hyperparameter Tuning with Grid Search:**\n",
    "A simple hyperparameter tuning approach using grid search is demonstrated for the RandomForestRegressor. Different combinations of hyperparameters are tested using cross-validation to identify the best set of values. The resulting model with the optimal hyperparameters is then evaluated on the test set.\n",
    "\n",
    "- Random Forest with Cross-Validation RMSE: 202.9\n",
    "\n",
    "**Best Random Forest Parameters:**\n",
    "- bootstrap: True\n",
    "- cacheNodeIds: False\n",
    "- checkpointInterval: 10\n",
    "- featureSubsetStrategy: auto\n",
    "- featuresCol: features\n",
    "- impurity: variance\n",
    "- labelCol: price\n",
    "- leafCol: \n",
    "- maxBins: 32\n",
    "- maxDepth: 15\n",
    "- maxMemoryInMB: 256\n",
    "- minInfoGain: 0.0\n",
    "- minInstancesPerNode: 5\n",
    "- minWeightFractionPerNode: 0.0\n",
    "- numTrees: 100\n",
    "- predictionCol: prediction\n",
    "- seed: 42\n",
    "- subsamplingRate: 1.0\n",
    "\n",
    "This example serves as a basic introduction to Spark and MLflow, providing a foundation for more advanced analyses and machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5737b9e-c773-4127-b8c7-3a3855172adf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Spark initialization\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, IntegerType, StringType\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, Imputer, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"sparkAirbnb\").getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "datasetPath = \"airbnb\"\n",
    "airbnbDF = spark.read.format(\"parquet\").load(datasetPath)\n",
    "\n",
    "# Display the schema\n",
    "airbnbDF.printSchema()\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "categoricalCols = [field for (field, dataType) in airbnbDF.dtypes if dataType == \"string\"]\n",
    "numericCols = [field for (field, dataType) in airbnbDF.dtypes if ((dataType == \"double\") and (field != \"price\"))]\n",
    "\n",
    "# Numeric pipeline\n",
    "imputer_numeric = Imputer(strategy=\"median\", inputCols=numericCols, outputCols=[\"{}_imputed\".format(col) for col in numericCols])\n",
    "assembler_numeric = VectorAssembler(inputCols=[\"{}_imputed\".format(col) for col in numericCols], outputCol=\"numeric_features\")\n",
    "scaler = StandardScaler(inputCol=\"numeric_features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "numeric_pipeline = Pipeline(stages=[imputer_numeric, assembler_numeric, scaler])\n",
    "numeric_transformed_df = numeric_pipeline.fit(airbnbDF).transform(airbnbDF)\n",
    "\n",
    "# Categorical pipeline\n",
    "indexOutputCols = [x + \"Index\" for x in categoricalCols]\n",
    "oheOutputCols = [x + \"OHE\" for x in categoricalCols]\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=indexOutputCols, handleInvalid=\"skip\")\n",
    "oheEncoder = OneHotEncoder(inputCols=indexOutputCols, outputCols=oheOutputCols)\n",
    "assemblerInputs = oheOutputCols + [\"scaled_features\",]\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "combined_pipeline = Pipeline(stages=[numeric_pipeline, stringIndexer, oheEncoder, vecAssembler])\n",
    "transformedDF = combined_pipeline.fit(airbnbDF).transform(airbnbDF)\n",
    "\n",
    "# Split into train and test sets\n",
    "trainDF, testDF = transformedDF.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"price\")\n",
    "lr_model = lr.fit(trainDF)\n",
    "\n",
    "# RandomForestRegressor\n",
    "rf = RandomForestRegressor(featuresCol='features', labelCol='price', numTrees=100, seed=42)\n",
    "rf_model = rf.fit(trainDF)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predDF_lr = lr_model.transform(testDF)\n",
    "predDF_rf = rf_model.transform(testDF)\n",
    "\n",
    "# Display predictions\n",
    "predDF_lr.select(\"features\", \"price\", \"prediction\").withColumn(\"prediction\", expr(\"abs(prediction)\")).show(10)\n",
    "predDF_rf.select(\"features\", \"price\", \"prediction\").withColumn(\"prediction\", expr(\"abs(prediction)\")).show(10)\n",
    "\n",
    "# Evaluate models\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price\", metricName=\"rmse\")\n",
    "rmse_lr = evaluator.evaluate(predDF_lr)\n",
    "rmse_rf = evaluator.evaluate(predDF_rf)\n",
    "\n",
    "print(f\"Linear Regression RMSE: {rmse_lr:.1f}\")\n",
    "print(f\"Random Forest RMSE: {rmse_rf:.1f}\")\n",
    "\n",
    "# MLflow logging\n",
    "import os\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import pandas as pd\n",
    "\n",
    "# Log parameters and metrics with MLflow\n",
    "with mlflow.start_run(run_name=\"random-forest\") as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model\", \"RandomForestRegressor\")\n",
    "    mlflow.log_params({param.name: value for param, value in rf_model.extractParamMap().items()})\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.spark.log_model(rf_model, \"random_forest_model\")\n",
    "\n",
    "    # Log metrics\n",
    "    evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price\", metricName=\"rmse\")\n",
    "    rmse_lr = evaluator.evaluate(lr_model.transform(testDF))\n",
    "    mlflow.log_metric(\"rmse_lr\", rmse_lr)\n",
    "    \n",
    "    rmse_rf = evaluator.evaluate(rf_model.transform(testDF))\n",
    "    mlflow.log_metric(\"rmse_rf\", rmse_rf)\n",
    "\n",
    "    # Log artifact: feature importance scores\n",
    "    rfModel = rf_model\n",
    "    pandasDF = (pd.DataFrame(list(zip(vecAssembler.getInputCols(), rfModel.featureImportances)), \n",
    "                             columns=[\"feature\", \"importance\"])\n",
    "                .sort_values(by=\"importance\", ascending=False))\n",
    "    \n",
    "    pandasDF.to_csv(\"data/feature-importance.csv\", index=False)\n",
    "    mlflow.log_artifact(\"data/feature-importance.csv\")\n",
    "\n",
    "# Simple fine-tuning\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid_rf = (\n",
    "    ParamGridBuilder() \n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \n",
    "    .addGrid(rf.minInstancesPerNode, [1, 5, 10]) \n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Cross-validation with the evaluator\n",
    "crossval_rf = CrossValidator(estimator=rf,\n",
    "                             estimatorParamMaps=param_grid_rf,\n",
    "                             evaluator=evaluator,\n",
    "                             numFolds=3)\n",
    "\n",
    "# Fit the Random Forest model with cross-validation on the training data\n",
    "cv_model_rf = crossval_rf.fit(trainDF)\n",
    "# Make predictions on the test set using the best Random Forest model\n",
    "predDF_rf_cv = cv_model_rf.transform(testDF)\n",
    "\n",
    "predDF_rf_cv.select(\"features\", \"price\", \"prediction\").withColumn(\"prediction\", expr(\"abs(prediction)\")).show(10)\n",
    "rmse_rf_cv = evaluator.evaluate(predDF_rf_cv)\n",
    "\n",
    "print(f\"Random Forest with Cross-Validation RMSE: {rmse_rf_cv:.1f}\")\n",
    "\n",
    "best_params_rf = cv_model_rf.bestModel.extractParamMap()\n",
    "print(\"Best Random Forest Parameters:\")\n",
    "for param, value in best_params_rf.items():\n",
    "    print(f\"{param.name}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
